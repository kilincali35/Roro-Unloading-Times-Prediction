{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python script uses the pickled best base model. Retrieves data from database automatically, then makes predictions on these live data. At the end, writes these predictions into a results table inside database. \n",
    "\n",
    "This script is set to run periodically with the use of Microsoft Task Scheduler. It runs at predetermined times and writes predictions into database. \n",
    "\n",
    "** I didn't run this Jupyter file properly because I masked all the critical info about our database. So, database retriaval part did not run as it was in real time. But when I enter the information into dsn and Oracle sections, it runs properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali.kilinc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ali.kilinc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\ali.kilinc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#this version is for real time prediction of updated data; using the pickled base model.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',40)\n",
    "import timeit\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "\n",
    "np.random.seed(234)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "start_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "ORA-12545: Connect failed because target host or object does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-da488b57121b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#conn = cx_Oracle.connect(\"...\", \"...\", \"...\",encoding = \"UTF-8\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdsnStr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcx_Oracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedsn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcx_Oracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdsnStr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     query = '''\n",
      "\u001b[1;31mDatabaseError\u001b[0m: ORA-12545: Connect failed because target host or object does not exist"
     ]
    }
   ],
   "source": [
    "#part where csv file is read\n",
    "#unloadx = pd.read_csv(r'C:\\Users\\ali.kilinc\\Desktop\\Roro Bo≈üaltma Tahminleme\\Test_Data.csv', index_col= False, encoding= 'unicode_escape')\n",
    "\n",
    "import pandas as pd\n",
    "import cx_Oracle\n",
    "#conn = cx_Oracle.connect(\"...\", \"...\", \"...\",encoding = \"UTF-8\")\n",
    "dsnStr = cx_Oracle.makedsn(\"...\", \"...\", \"...\")\n",
    "conn = cx_Oracle.connect(user = \"...\", password = \"...\", dsn = dsnStr, encoding=\"UTF-8\")\n",
    "try:\n",
    "    query = '''\n",
    "         SELECT * from vw_roro_unloading_input\n",
    "             '''\n",
    "    unload = pd.read_sql(con = conn, sql = query)\n",
    "finally:\n",
    "    conn.close()\n",
    "print(unload.head())\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-94c230e749d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#unload = unload.iloc[0:1000,:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POSITION_CODE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POSITION_CODE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#while retrieving data from CSV, leading 0's are missing, this line refills these 0's if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POSITION_CODE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POSITION_CODE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POSITION_CODE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POSITION_CODE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unload' is not defined"
     ]
    }
   ],
   "source": [
    "inp_transform = 0\n",
    "#unload = unload.iloc[0:1000,:]\n",
    "\n",
    "unload['POSITION_CODE'] = unload['POSITION_CODE'].astype('str')\n",
    "#while retrieving data from CSV, leading 0's are missing, this line refills these 0's if needed\n",
    "unload['POSITION_CODE'][unload['POSITION_CODE'].str[:1].str.isnumeric() == True] = unload['POSITION_CODE'][unload['POSITION_CODE'].str[:1].str.isnumeric() == True].str.zfill(8)\n",
    "\n",
    "print(unload.info())\n",
    "\n",
    "unload.dropna(subset=['RIDE_TYPE_ID'], inplace = True)\n",
    "\n",
    "unload['POSITION_CODE'] = unload['POSITION_CODE'].astype('str')\n",
    "unload['RIDE_TYPE_ID'] = unload['RIDE_TYPE_ID'].astype('int')\n",
    "unload['RIDE_TYPE_ID'] = unload['RIDE_TYPE_ID'].astype('category')\n",
    "unload['RIDE_TYPE_ID'] = unload['RIDE_TYPE_ID'].apply(str)\n",
    "unload['SERVICE_TYPE'] = unload['SERVICE_TYPE'].astype('object')\n",
    "unload['ROUTE_MODE'] = unload['ROUTE_MODE'].astype('category')\n",
    "unload['DOC_TYPE'] = unload['DOC_TYPE'].astype('category')\n",
    "unload['TRADELANE'] = unload['TRADELANE'].astype('category')\n",
    "unload['FIRST_UNL'] = unload['FIRST_UNL'].astype('category')\n",
    "unload['MIN_DUE'] = pd.to_datetime(unload['MIN_DUE'], format = '%d/%m/%Y %H:%M:%S')\n",
    "#unload['STARTED_DATE'] = pd.to_datetime(unload['STARTED_DATE'], format = '%d/%m/%Y %H:%M:%S')\n",
    "unload['ARRIVAL_DATE'] = pd.to_datetime(unload['ARRIVAL_DATE'], format = '%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "unload['UNL_MONTH'] = unload['ARRIVAL_DATE'].dt.month.astype('category')\n",
    "unload['UNL_MONTH'] = unload['UNL_MONTH'].apply(str)\n",
    "unload['UNL_DAY'] = (unload['ARRIVAL_DATE'].dt.weekday + 1).astype('category')\n",
    "unload['UNL_DAY'] = unload['UNL_DAY'].apply(str)\n",
    "unload['UNL_HOUR'] = unload['ARRIVAL_DATE'].dt.hour.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9fa560c1e518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msub_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msub_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UNL_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UNL_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msub_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msub_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_lowest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UNL_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UNL_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UNL_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unload' is not defined"
     ]
    }
   ],
   "source": [
    "sub_bins = [0, 2, 5, 8, 11, 14, 17, 20, 23]\n",
    "sub_labels = [1,2,3,4,5,6,7,8]\n",
    "unload['UNL_HOUR'] = pd.cut(unload['UNL_HOUR'], bins=sub_bins, labels=sub_labels, include_lowest = True)\n",
    "unload['UNL_HOUR'] = unload['UNL_HOUR'].apply(str)\n",
    "print(unload['UNL_HOUR'].head(50))\n",
    "\n",
    "\n",
    "#!!!!!!!! IT IS THE TRANSFORMATION OF CYCLICAL VARIABLES LIKE MONTH AND QUARTER. ONE-HOT IS AN OPTION BUT IT IS MUCH MORE BETTER THAN ENCODING\n",
    "unload['UNL_MONTH_X'] = np.sin(2*np.pi*unload['UNL_MONTH'].astype(int)/12)\n",
    "unload['UNL_MONTH_Y'] = np.cos(2*np.pi*unload['UNL_MONTH'].astype(int)/12)\n",
    "\n",
    "unload['UNL_DAY_X'] = np.sin(2*np.pi*unload['UNL_DAY'].astype(int)/7)\n",
    "unload['UNL_DAY_Y'] = np.cos(2*np.pi*unload['UNL_DAY'].astype(int)/7)\n",
    "\n",
    "unload['UNL_HOUR_X'] = np.sin(2*np.pi*unload['UNL_HOUR'].astype(int)/len(sub_labels))\n",
    "unload['UNL_HOUR_Y'] = np.cos(2*np.pi*unload['UNL_HOUR'].astype(int)/len(sub_labels))\n",
    "\n",
    "unload.drop(columns = ['UNL_MONTH', 'UNL_DAY', 'UNL_HOUR'], axis = 1, inplace = True)\n",
    "\n",
    "\"\"\" # General function for this transformation\n",
    "def encode(data, col, max_val): # max val is theoretical maximum of column, for month it is 12, for day of year it is 365 etc.\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6d6a113abd80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m unload['TIME_DUE'] = (round((unload['MIN_DUE'] - unload['ARRIVAL_DATE']).dt.seconds/60,0)\n\u001b[0m\u001b[0;32m      2\u001b[0m                             + (unload['MIN_DUE'] - unload['ARRIVAL_DATE']).dt.days*24*60).astype('int')\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'T_CUST_TRI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TRIESTE_CNT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LANECNT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TIME_DUE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'T_CUST_TRI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TRIESTE_CNT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LANECNT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TIME_DUE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unload' is not defined"
     ]
    }
   ],
   "source": [
    "unload['TIME_DUE'] = (round((unload['MIN_DUE'] - unload['ARRIVAL_DATE']).dt.seconds/60,0)\n",
    "                            + (unload['MIN_DUE'] - unload['ARRIVAL_DATE']).dt.days*24*60).astype('int')\n",
    "\n",
    "\n",
    "unload[['T_CUST_TRI', 'TRIESTE_CNT', 'LANECNT', 'TIME_DUE']] = unload[['T_CUST_TRI', 'TRIESTE_CNT', 'LANECNT', 'TIME_DUE']].astype(int)\n",
    "\n",
    "drop_false_due = unload[(unload['TIME_DUE'] < -30000) | (unload['TIME_DUE'] > 30000)].index\n",
    "unload.drop(index = drop_false_due, axis = 0, inplace = True)\n",
    "\n",
    "unload['DOC_TYPE'] = np.where(~unload['DOC_TYPE'].isin(['T-1', 'TR']), 'oth', unload['DOC_TYPE'])\n",
    "print(unload['DOC_TYPE'].value_counts())\n",
    "#contains also can be used I think as an alternative\n",
    "#why it is not working, work on it. For numeric condition like len(x) < 5 it is working.\n",
    "#unload['DOC_TYPE'] = unload['DOC_TYPE'].replace(unload.groupby('DOC_TYPE').filter(lambda x: unload['DOC_TYPE'].isin(['T-1', 'TR']) == False)['DOC_TYPE'], 'oth')\n",
    "\n",
    "unload.drop(columns = ['STARTED_DATE'], axis = 1, inplace = True)\n",
    "# drop=True makes ure that we are not keeping old indexes as a column, Drops that old index column\n",
    "print(unload.head())\n",
    "unload.dropna(inplace=True)\n",
    "unload.reset_index(drop=True, inplace = True)\n",
    "print(unload.info())\n",
    "\n",
    "df_pos_code = unload.reset_index()\n",
    "df_pos_code = df_pos_code[['index', 'POSITION_CODE']]\n",
    "print(df_pos_code)\n",
    "\n",
    "\n",
    "df_x = unload.drop(columns = ['ARRIVAL_DATE', 'MIN_DUE', 'POSITION_CODE'], axis=1)\n",
    "\n",
    "#df_x.drop(columns = ['TRIESTE_CNT', 'T_CUST_TRI', 'SERVICE_TYPE', 'LANECNT', 'TRADELANE', 'DOC_TYPE', 'UNL_HOUR', 'UNL_DAY', 'UNL_MONTH', 'RIDE_TYPE_ID', 'FIRST_UNL'], axis = 1, inplace = True)\n",
    "df_x.drop(columns = ['TRIESTE_CNT', 'T_CUST_TRI', 'SERVICE_TYPE', 'LANECNT', 'TRADELANE', 'DOC_TYPE'], axis = 1, inplace = True)\n",
    "\n",
    "df_x = pd.DataFrame(df_x, columns = df_x.columns)\n",
    "print(df_x.info())\n",
    "\n",
    "#it is valuable to transform independent variables to decrease skewness etc\n",
    "if inp_transform == 1:\n",
    "    tr_cols = ['LANECNT']\n",
    "    df_x[tr_cols] = np.log1p(df_x[tr_cols])\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-90f3c64f6617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\ali.kilinc\\Desktop\\Roro Bo≈üaltma Tahminleme\\best_model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mfinal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#file = open(r'C:\\Users\\ali.kilinc\\Desktop\\Roro Bo≈üaltma Tahminleme\\best_model.pkl', 'rb')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "with open(r'C:\\Users\\ali.kilinc\\Desktop\\Roro Bo≈üaltma Tahminleme\\best_model.pkl', 'rb') as f:\n",
    "        final_model = pickle.load(open('best_model.pkl', 'rb'))\n",
    "\n",
    "#file = open(r'C:\\Users\\ali.kilinc\\Desktop\\Roro Bo≈üaltma Tahminleme\\best_model.pkl', 'rb')\n",
    "#final_model = pickle.load(file)\n",
    "\n",
    "  \n",
    "#final_model = pd.read_pickle(r'C:\\Users\\ali.kilinc\\Desktop\\Roro Bo≈üaltma Tahminleme\\best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ae0e8f61c54e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PRED'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pos_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred = final_model.predict(df_x)\n",
    "df_x['PRED'] = np.exp(pred)\n",
    "\n",
    "df_x = pd.merge(df_pos_code, df_x, right_index = True, left_on = 'index')\n",
    "\n",
    "df_x = df_x.drop(columns = ['index'], axis = 1)\n",
    "\n",
    "timenow = time.time()\n",
    "timeobj = time.localtime(timenow)\n",
    "\n",
    "#it is the flag for each different prediction run\n",
    "idd = str(timeobj.tm_year) + str(timeobj.tm_mon) + str(timeobj.tm_mday) + str(timeobj.tm_hour) + str(timeobj.tm_min) + str(timeobj.tm_sec)\n",
    "\n",
    "df_x.insert(0, 'RUN_ID', idd)\n",
    "\n",
    "print(df_x)\n",
    "print(df_x.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-516fe7f9f237>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint_excel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\ali.kilinc\\Desktop\\PredUnload.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'FullTable'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_x' is not defined"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "print_excel = df_x.to_excel(r'C:\\Users\\ali.kilinc\\Desktop\\PredUnload.xlsx', index = None, header = True, sheet_name = 'FullTable')\n",
    "\n",
    "\n",
    "\n",
    "dsnStr = cx_Oracle.makedsn(\"...\", \"...\", \"...\")\n",
    "engine = create_engine('oracle+cx_oracle://...')\n",
    "\n",
    "conn = cx_Oracle.connect(user = \"...\", password = \"...\", dsn = dsnStr, encoding=\"UTF-8\")\n",
    "\n",
    "df_x.to_sql('UNLOAD_PREDICTION_TRIESTE', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
